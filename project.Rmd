---
title: "Building a Hotel Booking Cancellation Prediction Model"
author: "Giselle Ramirez"
output: 
  html_document:
    code_folding: hide
date: "2022-12-06"
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

![]()

![](images/hotel_booking_pic.jpg)

## Introduction

The purpose of this project is to build machine learning models that can accurately predict whether a hotel guest would cancel their hotel booking. The data that would be used is from '`hotel_booking`', and I will build different models that would most accurately predict the binary regression problem.

## Hotel Booking Process

Guests from all over the world are visiting hotels for different reasons. It could range to personal vacation ventures to business trips. In order to book a hotel, the guest must provide information about themselves and what kind of booking they are looking for. For example, they need to provide information on what day and how long they are looking to book the room(s). Also, who is coming along with them, along with other personal information they are looking to get from the hotel, such as parking and special accommodations. Hotels keep track of this and save the guest the room they asked for. However, there are times for any reason where hotel guests cancel their reservation. Hotels, in this case, must cancel the booking for the guest.

```{r}
library(vembedr)
embed_youtube("oUv2BcxAvjQ")
```

## **Why is this model important?**

In this dataset, we are exploring only two hotels: Resort Hotel and City Hotel, which are the closest hotels in the area. In order to keep track of when and if hotel guests will check in, it's important to keep track of hotel booking cancellations. Also, we need to see if certain guest traits will have a higher chance of cancellation so that hotels can be prepared just in case there might be a cancellation.

## **Project Roadmap**

I plan to build a logistic regression, linear discriminant analysis (LDA), decision tree, and boosted tree models. I will use roc_auc to compare all four models as roc_auc can provide a visual on how our models can distinguish between canceled and noncancelled hotel booking reservations.

## Exploratory Data Analysis

We need to clean up the data and choose our important variables that are relevant to predicting hotel booking cancellation.

### Loading Packages and Data

The dataset was found on Kaggle from Jeese Mostipak, but the [hotel_booking](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand) dataset was originally found from an article "Hotel Booking Demand Datasets" by Nuno Antonio, Ana Almedia, and Luis Nunes 2018. The original dataset contains 119390 observations/guests with 32 variables.

However, I will only use the variables that I believe are relevant to predicting hotel booking cancellations. In our case, is_canceled is our response variable, while the other variables are the predictors:

-   `hotel`: Which hotel --\> Resort Hotel or City Hotel
-   `is_canceled`: Whether hotel guest cancelled (1) or didn't cancel (0)
-   `lead_time`: Number of days hotel guest booked reservation in advance
-   `arrival_date_year`: Year of arrival
-   `arrival_date_month`: Month of arrival
-   `arrival_date_week`: Week of arrival (out of 52 weeks in a year)
-   `arrival_date_day_of_month`: Number of day in a Month
-   `stays_in_weekend_nights`: How many weekend nights (Saturday and Sunday) hotel guest stayed over
-   `stays_in_week_nights`: How many week nights (Monday to Friday)
-   `adults`: Number of adults checking in
-   `children`: Number of children checking in
-   `babies`: Number of babies checking in
-   `meal`: Type of meal package ordered (Undefined/SC - no meal package, BB - Bed and Breakfast, HB - Half board (two meals a day), FB - Full board (three meals a day))
-   `country`: Which country guest comes from (format: ISO 3155-3:2013), e.g. PRT = Portugal
-   `market_segment`: How people ordered their hotel booking (Online TA (Travel Agent), Offline TA/TO (Tour Operator), Direct, Corporate, Complementary, Groups, Undefined, Aviation)
-   `distribution_channel`: How booking was reserved (Direct, Corporate, TA/TO, Undefined, GDS)
-   `is_repeated_guest`: Not the first time the hotel guest made another hotel booking (1) or first time hotel guest (0)
-   `previous_cancellations:` Number of previous cancellations by guest before current hotel booking
-   `previous_booking_not_canceled`: Number of previous hotel bookings by guest NOT CANCELLED before current hotel booking
-   `reserved_room_type`: Type of room reserved (C, A, D, E, G, F, H, L, P, B)
-   `assigned_room_type`: Type of room assigned (may differ due to overbooking or room upgrades) (C, A, D, E, G, F, H, L, P, B, I, K)
-   `booking_changes`: Number of hotel booking changes when room(s) were booked until checkout
-   `deposit_type`: If hotel guest left deposit ("No Deposit" - none made, "Refundable" - deposit made was worth less of hotel stay, "Non Refund" - deposit made was made of entire hotel stay cost)
-   `agent`: Identification of travel agency that reserved hotel booking for guest
-   `company`: Identification of company that made booking
-   `days_in_waiting_list`: Number of days on waitlist before getting accepted to a hotel booking reservation
-   `customer_type`: Type of booking made (Transient - short and urgent booking for individual, Contract - signed contract for long stay booking, Transient-Party - short and urgent booking for a group, Group - booking for a group)
-   `adr`: Average Daily Rate (total cost of booking divided by number of days)
-   `required_car_parking_spaces:` Number of car parking spaces reserved by hotel guest
-   `total_of_special_request`: Number of total special requests made by hotel guest
-   `reservation_status:` Final reservation status (Check-Out - Hotel guest checked in and left at end of reservation booking, Canceled - hotel booking cancelled, No-Show - never showed up)
-   `reservation_status_date`: Date of final reservation status

### Libraries and Dataset Cleaning

```{r include=FALSE, results=}
library(tidymodels)
library(tidyverse)
library(dplyr)
library(corrr)
library(corrplot)
library(ggplot2)
library(discrim)
library(klaR)
library(glmnet)
library(ISLR)
library(rpart.plot)
library(vip)
library(randomForest)
library(xgboost)
library(ranger)
library(tidyr)
library(janitor)
library(knitr)
library(MASS)
library(vembedr)
library(poissonreg)
library(yardstick)
library(knitr)
library(kknn)
tidymodels_prefer()
```

```{r}
hotel_booking <- read.csv("data/hotel_bookings.csv") 
set.seed(1234)
hotel_booking %>%
  head()
```

Let's see the dimensions of this dataset.

```{r}
dim(hotel_booking)
```

So we have 119390 individuals that booked hotel reservations and 32 original variables.

Let's see which variables have missing values so that we could replace null values with 0 or unknown. And make sure there is at least one person per hotel booking (so children, adults, and babies cannot be all 0).

```{r}
numeric_book <- unlist(lapply(hotel_booking, is.integer))
data_num <- hotel_booking[, numeric_book]
#data_num
(colMeans(is.na(data_num))) *100

character_book <- unlist(lapply(hotel_booking, is.character))
data_chara <- hotel_booking[, character_book]

sum(is.na(hotel_booking$children)) #4 missing

#count by group

null_country <- data_chara %>%
  group_by(country) %>%
  summarize(n()) %>%
  filter(country == "NULL") %>%
  select('n()')
null_country #488

null_agent <- data_chara %>%
  group_by(agent) %>%
  summarize(n()) %>%
  filter(agent == "NULL") %>%
  select('n()')
null_agent #16340

null_comp <- data_chara %>%
  group_by(company) %>%
  summarize(n()) %>%
  filter(company == "NULL") %>%
  select('n()')
null_comp #112593
```

Based on the code, we see that there are some missing values for children (4), country (488), agent (16340), and company (112593). Due to this, we will fill in 0 for children, agent, and company, and fill in 'UNK' as unknown for country. We will also filter out any hotel room bookings that have zero adults, children, and babies.

```{r}
hotel_booking$children[is.na(hotel_booking$children)] <- 0
hotel_booking$agent <- hotel_booking$agent %>% replace(.=="NULL", "0") 
hotel_booking$company <- hotel_booking$company %>% replace(.=="NULL", "0") 
hotel_booking$country <- hotel_booking$country %>% replace(.=="NULL", "UNK") 
hotel_booking <- hotel_booking %>%
  filter((adults > 0 & babies == 0 & children == 0) |
           (adults == 0 & babies>0 & children == 0) |
           (adults == 0 & babies == 0 & children > 0) |
           (adults >0 | babies >0 | children >0))
head(hotel_booking)
```

Also, I want to make some character variables into numerical variables that I can analyze better. and separate reservation_status_date into year, month, and day in order to analyze the updated date of the hotel booking reservation. I will also factor variables that have levels in order:

```{r}
#ignore warning please
data_chara <- hotel_booking[, unlist(lapply(hotel_booking, is.character))]
colnames(data_chara) #character variables 
#(not include country, agent, company, and reservation_status_date since #there's a lot of unique values for these variables)
list_unique <- data_chara %>%
  select(-country, -agent, -company, -reservation_status_date) %>%
  lapply(unique)
  
hotel_booking <- hotel_booking %>%
  mutate(
    hotel = recode(hotel, 'Resort Hotel' = 0, 'City Hotel' = 1),
    arrival_date_month = recode(arrival_date_month, "January" = 1, 
                                "February" = 2, "March" = 3, 
                                "April" = 4, "May" = 5, "June" = 6, 
                                "July" = 7,"August" = 8, "September" = 9, 
                                "October" = 10, "November" = 11, 
                                "December" = 12),
    meal = recode(meal, "Undefined" = 0, "SC" = 1, "BB" = 2, "HB" = 3, 
                  "FB" = 4), 
    market_segment = recode(market_segment, "Direct" = 0, "Corporate" = 1, 
                            "Online TA" = 2, "Offline TA/TO" = 3, 
                            "complementary" = 4, "Groups" = 5, 
                            "Aviation" = 6, "Undefined" = 7), 
    distribution_channel = recode(distribution_channel, "Direct" = 0, 
                                  "Corporate" = 1, "TA/TO" = 2, 
                                  "Undefined" = 3, "GDS" = 4), 
    reserved_room_type = recode(reserved_room_type, "C" = 0, "A" = 1, 
                                "D" = 2, "E" = 3, "G" = 4, "F" = 5, 
                                "H" = 6, "L" = 7, "B" = 8), 
    assigned_room_type = recode(assigned_room_type, "C" = 0, "A" = 1, 
                                "D" = 2, "E" = 3, "G" = 4, "F" = 5, 
                                "I" = 6, "B" = 7, "H" = 8, "L" = 9, 
                                "K" = 10), 
    deposit_type = recode(deposit_type, "No Deposit" = 0, "Refundable" = 1, 
                          "Non Refund" = 2), 
    customer_type = recode(customer_type, "Transient" = 0, "Contract" = 1, 
                           "Transient-Party" = 2, "Group" = 3), 
    reservation_status = recode(reservation_status, "Check-Out" = 0, 
                                "Canceled" = 1, "No-Show" = 2)) %>% 
  separate(reservation_status_date, c("latest_year", "latest_month", 
                                      "latest_day")) %>% 
  mutate(
    hotel = factor(hotel), 
    meal = factor(meal), 
    market_segment = factor(market_segment),
    distribution_channel = factor(distribution_channel), 
    reserved_room_type= factor(reserved_room_type),
    assigned_room_type = factor(assigned_room_type),
    deposit_type = factor(deposit_type), 
    customer_type = factor(customer_type), 
    reservation_status = factor(reservation_status), 
    is_canceled = factor(is_canceled),
    is_repeated_guest = factor(is_repeated_guest)
  )

head(hotel_booking)
```

## Testing and Training Datasets

Now our data is cleaned up and organized enough to do some EDA with our testing and training sets.

First, let's split our data to our testing and training sets with 80% training and 20% testing.

```{r}
booking_split <- hotel_booking %>%
  initial_split(prop = 0.8, strata = "is_canceled")

booking_train <- training(booking_split)
booking_test <- testing(booking_split)
```

The training set has around 95367 observations, while the testing set has around 23843 observations. Observations in this case are hotel bookings.

Now, let's explore the distribution of the outcome variable called is_canceled.

```{r}
booking_train %>%
  ggplot(aes(x = is_canceled)) +
  geom_bar()
```

As we see here, in our training set, we see that many hotel guests aren't canceling their hotel booking, which is marked by 0 and about 35000 hotel guests end up canceling their reservations.

I also want to see the correlation of all numeric continuous variables to see if they have relations with one another.

```{r}
booking_train %>%
  select_if(is.numeric) %>%
  select(-arrival_date_day_of_month, -babies, -booking_changes, -days_in_waiting_list, -required_car_parking_spaces) %>%
  cor(use = "complete.obs") %>%
  corrplot(order= "original", diag = FALSE)
#original, AOE, FPC, hclust, alphabet

```

I removed some numeric variables that had almost zero correlation with the rest of the numeric variables, which were arrival_date_day_of_month, babies, booking_changes, days_in_waiting_list, and required_car_parking_spaces. I will remove these variables for the recipe later as they are don't have much correlation with each other. As seen here, we see that arrival_date_month and arrival_date_week_number have a very strong positive correlation. This makes sense as when the months go by, so will the weeks. The variables stays_in_week_nights and stays_in_weekend_nights also had a moderate positive correlation, which also makes sense as there are some people that would stay a mix of weekday and weekend nights.

There is also a strong negative correlation between arrival_date_month and arrival_date_year and arrival_date_week_number with arrival_date_year. Both of these relations are interesting, because they suggest that there are more booking towards the later months/weeks of the year.

Let's do a histogram to see if this is true that there is more bookings towards the end of the year for the training set.

```{r}
month_book <- hotel_booking %>%
  count(arrival_date_month, hotel)
month_book

ggplot(month_book, aes(x = arrival_date_month, y = n, fill = hotel)) + 
  geom_bar(stat = "identity", position = 'dodge')
```

As we can see in the barchart above, from January to August, the hotel booking seems to increase and decreases as it approaches December for Resort Hotel (hotel = 0). However, for City Hotel (hotel = 1), the hotel booking seems to stay around the same, only peaking around August.

Now, that I saw the overall pattern of our hotel_booking dataset, lets set up our models!

### Making our Recipes

Now that we built our training and testing sets and observing if there is any correlation within the variables, we need to build a recipe that would be essential in building our models. I excluded variables that had almost no correlation with other variables (which include: `arrival_date_day_of_month`, `babies`, `booking_changes`, `days_in_waiting_list`, `required_car_parking_spaces`), had over 10% missing variables (`agent` and `company`). I also excluded variables that have an almost 100% correlation with the variable `is_canceled` , which are `reservation_status` (detail if the person did check in with the hotel or not), `assigned_room_type` (applies to people who have checked in who changed their room), `booking_changes` (number of changes made to the room once checked in), `days_in_waiting_list` (confirmed booking), etc. So in total, we will use only 20 of the predictor variables.

```{r}
booking_recipe <- recipe(is_canceled ~ hotel + arrival_date_week_number + stays_in_weekend_nights + stays_in_week_nights + adults + children + meal + market_segment + distribution_channel + is_repeated_guest + previous_cancellations + previous_bookings_not_canceled + reserved_room_type + deposit_type + customer_type + adr + required_car_parking_spaces + latest_year + latest_month + latest_day, data = booking_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
```

### K-Fold Cross Validation

Now we are going to use cross-validation to fold the training set as a stratified cross-validation with repeats. We are using 5 folds.

```{r}
booking_folds <- vfold_cv(booking_train, v = 5, strata = is_canceled)
```

## Model Building

Now it is time to build our models! We will use roc_auc as a metric set across our models to see which is our best model. Our models are logistic regression, linear discriminant analysis, decision tree, and a boosted tree for this binary classification problem.

Let's first start off with building a logistic regression.

### Logistic Regression

First we need to build a logistic regression model with a workflow. Then, we need to fit it to our folds!

```{r}
log_reg <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

log_wkflow <- workflow() %>%
  add_model(log_reg) %>%
  add_recipe(booking_recipe)

log_fit <- fit_resamples(log_wkflow, booking_folds)
```

Next, we are going to select the best roc_auc among our folds, which in this case was our fifth fold!

```{r}
log_roc <- collect_metrics(log_fit) %>%
  arrange(desc(mean)) %>%
  slice(1)
log_roc
```

We see that log_fit has a roc_auc of 0.84401. This is pretty high! Let's see for our next model of linear discriminant analysis.

### Linear Discriminant Analysis

First, we need to create a lda model with a workflow. Next, we find the fit for the lda using our folds from earlier. Then we see our roc_auc.

```{r}
control <- control_resamples(save_pred = TRUE)
lda_mod <- discrim_linear() %>% 
  set_engine("MASS") %>% 
  set_mode("classification")

lda_wkflow <- workflow() %>% 
  add_recipe(booking_recipe) %>% 
  add_model(lda_mod)

lda_fit <- fit_resamples(resamples = booking_folds, 
                         lda_wkflow, control = control)
```

```{r}
lda_roc <- collect_metrics(lda_fit) %>%
  arrange(desc(mean)) %>%
  slice(1)
lda_roc
```

We see that lda_fit has a roc_auc of 0.82643. Compared to log_reg, this is a bit lower roc_auc. So far log_fit looks to have the highest roc_auc so far! Let's look on our third model on decision tree!

### Decision Tree

We also create a model on a decision tree and create a workflow that I would later apply to our folds from earlier.

```{r}
tree_spec <- decision_tree() %>%
  set_engine("rpart")

class_tree_spec <- tree_spec %>%
  set_mode("classification") %>%
  set_args(cost_complexity = tune())

class_tree_wf <- workflow() %>%
  add_model(class_tree_spec) %>%
  add_recipe(booking_recipe)

param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 5)

decision_tree <- tune_grid(
  class_tree_wf,
  resamples = booking_folds, 
  grid = param_grid, 
  metrics = metric_set(roc_auc)
)

autoplot(decision_tree)
```

As seen here, after 0.0055 (between 0.001 and 0.01), we see that the line drastically lowers down to a roc_auc of about 0.73 and it's highest roc_auc was when the cost-complexity parameter was almost 0.90. Now let's see the roc_auc of our best decision tree.

```{r}
decision_roc <- decision_tree %>%
  collect_metrics() %>%
  arrange(desc(mean)) %>%
  slice(1)
decision_roc
```

We see that we have a roc_auc of 0.88685 of our best performing decision tree on the folds! This is higher than our LDA and linear regression!

Now let's see for boosted tree model if it's better than our decision tree.

### Boosted Tree Model

First, we must tune our trees and set a workflow for our boosted tree model. Then we set the range for the trees from 200 to 1200. Then we create our model and make an autoplot for it as shown below.

```{r}
boost_spec <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("classification") %>%
  set_args(trees = tune())

boost_wf <- workflow() %>%
  add_model(boost_spec) %>%
  add_recipe(booking_recipe) 

param_grid2 <- grid_regular(trees(range = c(200, 1200)), levels = 2)

boosted_tree <- tune_grid(
  boost_wf, 
  resamples = booking_folds, 
  grid = param_grid2, 
  metrics = metric_set(roc_auc)
)
autoplot(boosted_tree)
```

As shown above, it seems that the roc_auc is very close to 0 as it approaches 12500 trees. And if so, this could mean that the boosted tree model is the best model than the previous models.

```{r}
boosted_roc <- boosted_tree %>%
  collect_metrics() %>%
  arrange(desc(mean)) %>%
  slice(1)
boosted_roc
```

As shown here, at tree 12500, we see that our roc_auc is 0.99162, making this our best model.

## ROC AUC of Our Models

Let's make tibble that contains all roc_auc of all of our four models.

```{r}
result <- bind_rows(log_roc, lda_roc, decision_roc, boosted_roc) %>%
  tibble() %>%
  mutate(model = c('logistic regression model', 'linear determinant analysis model', 'decision tree model', 'boosted tree model'), 
         .before = .metric) %>%
  select(model, .metric, mean, n, std_err) %>%
  arrange(desc(mean))
result
```

Now, we can clearly see that the boosted tree model has the highest roc_auc, meaning our boosted tree model is able to accurately predict 99% of our hotel bookings if it would be canceled or not.

Let's display a barchart to see how far is the difference.

```{r}
result_chart <- ggplot(result, aes(x = model, y = mean)) +
  geom_bar(stat = "identity")
result_chart
```

We see that boosted tree model is the best model as it's roc_auc is almost to 1 while the other models are below 0.9. Now let's put test our model to our testing dataset.

## Best Model: Boosted Tree Model

Now let's test this model to our testing set!

First, we collect the metrics on our boosted tree model and select the best tree (tree 12500) and apply to to our testing model.

```{r}
final_penalty <- select_best(boosted_tree)

final_tree <- finalize_workflow(boost_wf, final_penalty)

final_fit <- fit(final_tree, data = booking_train)

final_roc_auc <- augment(final_fit, new_data = booking_test) %>%
  select(is_canceled, starts_with(".pred")) %>%
  roc_curve(is_canceled, estimate = .pred_0)
final_roc_auc

autoplot(final_roc_auc)
```

It has an extremely high roc_auc, which is almost perfect. Meaning there is very little false positives or true positives in this case, which means our boosted tree model was almost able to predict every single hotel booking cancellation in our testing data.

Now let's see the roc_auc for our model:

```{r}
roc_auc_final <- augment(final_fit, new_data = booking_test) %>%
  select(is_canceled, starts_with(".pred")) %>%
  roc_auc(is_canceled, .pred_0)
roc_auc_final
```

This has an roc_auc estimate of 0.99339! This is a very high accuracy!

## Conclusions

We started off wondering what are possible predictors that could determine the chances that a person would cancel their hotel booking reservations. After using over 20 predictors to our response variable of is_cancelled, we see that we can predict over 80% of cancellations for all our four models. Our log regression and linear discriminant analysis behaved the most poorly (although above 80%) compared to our other two models, which are decision trees and boosted trees (one almost 90% roc_auc and the latter with almost 100%). I used roc_auc in order to visualize around if our model was able to predict the correct cancellations for our hotel booking by visualizing the true positive rate and false positive rate.

I was not surprised as my most complicated model: boosted tree model took a long time to run and gave the best roc_auc. Next steps would be to explore which predictors were the ones that accurately predicted our hotel booking cancellations.

Overall, the boosted tree model is the best in this case for our binary classification problem.
